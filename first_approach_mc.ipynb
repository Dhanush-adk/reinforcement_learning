{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dhanush-adk/reinforcement_learning/blob/main/first_approach_mc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 245,
      "metadata": {
        "id": "a11knME64qlG"
      },
      "outputs": [],
      "source": [
        "class MoverEnvironment:\n",
        "    def __init__(self, size=7, eater_actions=None, eater_policy=None):\n",
        "        self.size = size\n",
        "        self.true_goal = (6, 6)  # True goal at (6, 6)\n",
        "        self.fake_goal = (1, 5)  # Fake goal at (1, 5)\n",
        "        self.initial_resources = 100  # High initial resource value for both goals\n",
        "        self.resources = {self.true_goal: self.initial_resources, self.fake_goal: self.initial_resources}\n",
        "        self.eater_actions = eater_actions or [(1, 0), (0, 1), (0.5, 0.5), (0.2, 0.8), (0.6, 0.4),\n",
        "                                               (0.8, 0.2), (0.4, 0.6), (0.7, 0.3), (0.3, 0.7)]\n",
        "        self.eater_policy = eater_policy or {}\n",
        "        self.moves = ['Up', 'Down', 'Left', 'Right']\n",
        "        self.visited_fake_goal = False\n",
        "        self.state = (0, 0)\n",
        "\n",
        "    def reset(self):\n",
        "        self.state = (0, 0)\n",
        "        self.resources = {self.true_goal: self.initial_resources, self.fake_goal: self.initial_resources}\n",
        "        self.visited_fake_goal = False\n",
        "        return self.state\n",
        "\n",
        "    def step(self, curr_state, action):\n",
        "        move_offsets = [(0, 1),(0, -1),(-1, 0), (1, 0)]\n",
        "        new_state = (curr_state[0] + move_offsets[action][0], curr_state[1] + move_offsets[action][1])\n",
        "\n",
        "        # Ensure the agent doesn't move out of bounds\n",
        "        new_state = (\n",
        "            max(0, min(new_state[0], self.size - 1)),\n",
        "            max(0, min(new_state[1], self.size - 1))\n",
        "        )\n",
        "\n",
        "        # Calculate the linear index for the eater policy\n",
        "        index = new_state[1] * self.size + new_state[0]\n",
        "\n",
        "\n",
        "        # Apply the eater action based on the eater policy or use a default action\n",
        "        eater_index = self.eater_policy.get((index, action), 0)\n",
        "        consumption = self.eater_actions[eater_index]\n",
        "        self.resources[self.true_goal] -= consumption[1]\n",
        "        self.resources[self.fake_goal] -= consumption[0]\n",
        "\n",
        "        # Update state\n",
        "        self.state = new_state\n",
        "        reward = -1  # Default step cost\n",
        "        deceive = (2,5)\n",
        "        # Logic for fake goal interaction\n",
        "        if self.state == deceive and not self.visited_fake_goal:\n",
        "            self.visited_fake_goal = True\n",
        "            reward += 50  # Reward for first visiting the fake goal\n",
        "        elif self.state == deceive:\n",
        "            reward += 40  # Reward for revisiting the fake goal\n",
        "\n",
        "        # Logic for true goal interaction\n",
        "        if self.state == self.true_goal:\n",
        "            if not self.visited_fake_goal:\n",
        "                reward -= 100  # Penalty for reaching true goal before fake goal\n",
        "            else:\n",
        "                reward += 815  # Big reward for reaching true goal after fake\n",
        "\n",
        "        # Check for resource depletion\n",
        "        if self.resources[self.true_goal] <= 0 or self.resources[self.fake_goal] <= 0:\n",
        "            reward -= 100  # Severe penalty for running out of resources\n",
        "\n",
        "        # Determine if the game is over (reaching the true goal)\n",
        "        done = self.state == self.true_goal\n",
        "\n",
        "        return self.state, reward, done\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Re9537V4SAzs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def generate_episode(env, policy, epsilon=0.1):\n",
        "    episode = []\n",
        "    current_state = env.reset()\n",
        "    done = False\n",
        "    while not done:\n",
        "        if random.random() < epsilon:\n",
        "            action = random.choice(range(4))\n",
        "        else:\n",
        "            action = policy[current_state] if current_state in policy else random.choice(range(4))\n",
        "        next_state, reward , done = env.step(current_state, action)\n",
        "        episode.append((current_state, action, reward))\n",
        "        current_state = next_state\n",
        "    return episode\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "\n",
        "def first_visit_mc(env, num_episodes, epsilon=0.1):\n",
        "    Q = {}\n",
        "    returns = {}\n",
        "    policy = {}\n",
        "    for x in range(7):\n",
        "        for y in range(7):\n",
        "            state = (x, y)\n",
        "            for action in range(4):\n",
        "                Q[(state, action)] = 0\n",
        "                returns[(state, action)] = []\n",
        "            policy[state] = random.choice(list(range(4)))\n",
        "    for episode_number in range(num_episodes):\n",
        "        if episode_number % 1 ==0:\n",
        "          print(episode_number)\n",
        "        episode = generate_episode(env, policy, epsilon)\n",
        "        G = 0\n",
        "        visited = set()\n",
        "        for (state, action, reward) in reversed(episode):\n",
        "            G = reward + 0.99 * G\n",
        "            if (state, action) not in visited:\n",
        "                visited.add((state, action))\n",
        "                returns[(state, action)].append(G)\n",
        "                Q[(state, action)] = np.mean(returns[(state, action)])\n",
        "                best_action = max((Q[(state, a)], a) for a in range(4))[1]\n",
        "                policy[state] = best_action\n",
        "\n",
        "    return policy, Q\n",
        "env = MoverEnvironment(\n",
        "    eater_policy=\n",
        "{(1, 0): 7, (1, 1): 7, (1, 2): 7, (1, 3): 7, (2, 0): 7, (2, 1): 7, (2, 2): 7, (2, 3): 7, (3, 0): 7, (3, 1): 7, (3, 2): 7, (3, 3): 7, (4, 0): 7, (4, 1): 7, (4, 2): 7, (4, 3): 7, (5, 0): 7, (5, 1): 7, (5, 2): 7, (5, 3): 7, (6, 0): 7, (6, 1): 7, (6, 2): 7, (6, 3): 7, (7, 0): 7, (7, 1): 7, (7, 2): 7, (7, 3): 7, (8, 0): 7, (8, 1): 7, (8, 2): 7, (8, 3): 7, (9, 0): 7, (9, 1): 7, (9, 2): 7, (9, 3): 7, (10, 0): 7, (10, 1): 7, (10, 2): 7, (10, 3): 7, (11, 0): 7, (11, 1): 7, (11, 2): 7, (11, 3): 7, (12, 0): 5, (12, 1): 5, (12, 2): 5, (12, 3): 5, (13, 0): 5, (13, 1): 5, (13, 2): 5, (13, 3): 5, (14, 0): 5, (14, 1): 5, (14, 2): 5, (14, 3): 5, (15, 0): 5, (15, 1): 5, (15, 2): 5, (15, 3): 5, (16, 0): 5, (16, 1): 5, (16, 2): 5, (16, 3): 5, (17, 0): 5, (17, 1): 5, (17, 2): 5, (17, 3): 5, (18, 0): 5, (18, 1): 5, (18, 2): 5, (18, 3): 5, (19, 0): 5, (19, 1): 5, (19, 2): 5, (19, 3): 5, (20, 0): 5, (20, 1): 5, (20, 2): 5, (20, 3): 5, (21, 0): 5, (21, 1): 5, (21, 2): 5, (21, 3): 5, (22, 0): 5, (22, 1): 5, (22, 2): 5, (22, 3): 5, (23, 0): 5, (23, 1): 5, (23, 2): 5, (23, 3): 5, (24, 0): 5, (24, 1): 5, (24, 2): 5, (24, 3): 5, (25, 0): 5, (25, 1): 5, (25, 2): 5, (25, 3): 5, (26, 0): 5, (26, 1): 5, (26, 2): 5, (26, 3): 5, (27, 0): 5, (27, 1): 5, (27, 2): 5, (27, 3): 5, (28, 0): 5, (28, 1): 5, (28, 2): 5, (28, 3): 5, (29, 0): 5, (29, 1): 5, (29, 2): 5, (29, 3): 5, (30, 0): 5, (30, 1): 5, (30, 2): 5, (30, 3): 5, (31, 0): 5, (31, 1): 5, (31, 2): 5, (31, 3): 5, (32, 0): 0, (32, 1): 5, (32, 2): 5, (32, 3): 5, (33, 0): 0, (33, 1): 5, (33, 2): 5, (33, 3): 5, (34, 0): 0, (34, 1): 5, (34, 2): 5, (34, 3): 5, (35, 0): 0, (35, 1): 5, (35, 2): 5, (35, 3): 5, (36, 0): 0, (36, 1): 5, (36, 2): 5, (36, 3): 5, (37, 0): 0, (37, 1): 5, (37, 2): 5, (37, 3): 5, (38, 0): 0, (38, 1): 5, (38, 2): 5, (38, 3): 5, (39, 0): 0, (39, 1): 5, (39, 2): 5, (39, 3): 8, (40, 0): 5, (40, 1): 5, (40, 2): 8, (40, 3): 8, (41, 0): 5, (41, 1): 4, (41, 2): 8, (41, 3): 8, (42, 0): 2, (42, 1): 8, (42, 2): 8, (42, 3): 8, (43, 0): 8, (43, 1): 8, (43, 2): 8, (43, 3): 8, (44, 0): 8, (44, 1): 8, (44, 2): 8, (44, 3): 8, (45, 0): 8, (45, 1): 8, (45, 2): 8, (45, 3): 8, (46, 0): 8, (46, 1): 8, (46, 2): 8, (46, 3): 8, (47, 0): 8, (47, 1): 8, (47, 2): 8, (47, 3): 8, (48, 0): 8, (48, 1): 8, (48, 2): 8, (48, 3): 3, (49, 0): 8, (49, 1): 8, (49, 2): 3, (49, 3): 1})\n",
        "estimated_policy, Q_values = first_visit_mc(env, 8500, 0.1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2apw7y5rSEwY",
        "outputId": "d566f77d-2733-4bb4-ffad-4bb0d0732ca2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{(0, 0): 3, (0, 1): 3, (0, 2): 2, (0, 3): 1, (0, 4): 0, (0, 5): 3, (0, 6): 2, (1, 0): 3, (1, 1): 1, (1, 2): 1, (1, 3): 0, (1, 4): 0, (1, 5): 1, (1, 6): 1, (2, 0): 3, (2, 1): 3, (2, 2): 1, (2, 3): 1, (2, 4): 1, (2, 5): 0, (2, 6): 3, (3, 0): 0, (3, 1): 3, (3, 2): 0, (3, 3): 1, (3, 4): 1, (3, 5): 1, (3, 6): 1, (4, 0): 2, (4, 1): 3, (4, 2): 1, (4, 3): 2, (4, 4): 1, (4, 5): 3, (4, 6): 0, (5, 0): 3, (5, 1): 0, (5, 2): 3, (5, 3): 1, (5, 4): 1, (5, 5): 3, (5, 6): 3, (6, 0): 0, (6, 1): 0, (6, 2): 0, (6, 3): 0, (6, 4): 0, (6, 5): 0, (6, 6): 1}\n"
          ]
        }
      ],
      "source": [
        "print(estimated_policy)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "moves = ['Up', 'Down', 'Left', 'Right']\n",
        "for i in estimated_policy:\n",
        "  print(i, moves[estimated_policy[i]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHl8372LM0ZK",
        "outputId": "baa6be4c-672b-4f13-ad98-5aebd679f96d"
      },
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, 0) Right\n",
            "(0, 1) Right\n",
            "(0, 2) Left\n",
            "(0, 3) Down\n",
            "(0, 4) Up\n",
            "(0, 5) Right\n",
            "(0, 6) Left\n",
            "(1, 0) Right\n",
            "(1, 1) Down\n",
            "(1, 2) Down\n",
            "(1, 3) Up\n",
            "(1, 4) Up\n",
            "(1, 5) Down\n",
            "(1, 6) Down\n",
            "(2, 0) Right\n",
            "(2, 1) Right\n",
            "(2, 2) Down\n",
            "(2, 3) Down\n",
            "(2, 4) Down\n",
            "(2, 5) Up\n",
            "(2, 6) Right\n",
            "(3, 0) Up\n",
            "(3, 1) Right\n",
            "(3, 2) Up\n",
            "(3, 3) Down\n",
            "(3, 4) Down\n",
            "(3, 5) Down\n",
            "(3, 6) Down\n",
            "(4, 0) Left\n",
            "(4, 1) Right\n",
            "(4, 2) Down\n",
            "(4, 3) Left\n",
            "(4, 4) Down\n",
            "(4, 5) Right\n",
            "(4, 6) Up\n",
            "(5, 0) Right\n",
            "(5, 1) Up\n",
            "(5, 2) Right\n",
            "(5, 3) Down\n",
            "(5, 4) Down\n",
            "(5, 5) Right\n",
            "(5, 6) Right\n",
            "(6, 0) Up\n",
            "(6, 1) Up\n",
            "(6, 2) Up\n",
            "(6, 3) Up\n",
            "(6, 4) Up\n",
            "(6, 5) Up\n",
            "(6, 6) Down\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 260,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQg3sE-shhSE",
        "outputId": "936e92d7-dd39-4c4c-8d3d-4f145a214c7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1: State: (0, 0),  action: Right, Next State: (1, 0), Reward: -1, resources : {(6, 6): 99.7, (1, 5): 99.3}\n",
            "Step 2: State: (1, 0),  action: Right, Next State: (2, 0), Reward: -1, resources : {(6, 6): 99.4, (1, 5): 98.6}\n",
            "Step 3: State: (2, 0),  action: Right, Next State: (3, 0), Reward: -1, resources : {(6, 6): 99.10000000000001, (1, 5): 97.89999999999999}\n",
            "Step 4: State: (3, 0),  action: Up, Next State: (3, 1), Reward: -1, resources : {(6, 6): 98.80000000000001, (1, 5): 97.19999999999999}\n",
            "Step 5: State: (3, 1),  action: Right, Next State: (4, 1), Reward: -1, resources : {(6, 6): 98.50000000000001, (1, 5): 96.49999999999999}\n",
            "Step 6: State: (4, 1),  action: Right, Next State: (5, 1), Reward: -1, resources : {(6, 6): 98.30000000000001, (1, 5): 95.69999999999999}\n",
            "Step 7: State: (5, 1),  action: Up, Next State: (5, 2), Reward: -1, resources : {(6, 6): 98.10000000000001, (1, 5): 94.89999999999999}\n",
            "Step 8: State: (5, 2),  action: Right, Next State: (6, 2), Reward: -1, resources : {(6, 6): 97.9, (1, 5): 94.1}\n",
            "Step 9: State: (6, 2),  action: Up, Next State: (6, 3), Reward: -1, resources : {(6, 6): 97.7, (1, 5): 93.3}\n",
            "Step 10: State: (6, 3),  action: Up, Next State: (6, 4), Reward: -1, resources : {(6, 6): 97.7, (1, 5): 92.3}\n",
            "Step 11: State: (6, 4),  action: Up, Next State: (6, 5), Reward: -1, resources : {(6, 6): 97.5, (1, 5): 91.5}\n",
            "Step 12: State: (6, 5),  action: Up, Next State: (6, 6), Reward: -101, resources : {(6, 6): 96.8, (1, 5): 91.2}\n"
          ]
        }
      ],
      "source": [
        "env = MoverEnvironment(\n",
        "    eater_policy=\n",
        "{(1, 0): 7, (1, 1): 7, (1, 2): 7, (1, 3): 7, (2, 0): 7, (2, 1): 7, (2, 2): 7, (2, 3): 7, (3, 0): 7, (3, 1): 7, (3, 2): 7, (3, 3): 7, (4, 0): 7, (4, 1): 7, (4, 2): 7, (4, 3): 7, (5, 0): 7, (5, 1): 7, (5, 2): 7, (5, 3): 7, (6, 0): 7, (6, 1): 7, (6, 2): 7, (6, 3): 7, (7, 0): 7, (7, 1): 7, (7, 2): 7, (7, 3): 7, (8, 0): 7, (8, 1): 7, (8, 2): 7, (8, 3): 7, (9, 0): 7, (9, 1): 7, (9, 2): 7, (9, 3): 7, (10, 0): 7, (10, 1): 7, (10, 2): 7, (10, 3): 7, (11, 0): 7, (11, 1): 7, (11, 2): 7, (11, 3): 7, (12, 0): 5, (12, 1): 5, (12, 2): 5, (12, 3): 5, (13, 0): 5, (13, 1): 5, (13, 2): 5, (13, 3): 5, (14, 0): 5, (14, 1): 5, (14, 2): 5, (14, 3): 5, (15, 0): 5, (15, 1): 5, (15, 2): 5, (15, 3): 5, (16, 0): 5, (16, 1): 5, (16, 2): 5, (16, 3): 5, (17, 0): 5, (17, 1): 5, (17, 2): 5, (17, 3): 5, (18, 0): 5, (18, 1): 5, (18, 2): 5, (18, 3): 5, (19, 0): 5, (19, 1): 5, (19, 2): 5, (19, 3): 5, (20, 0): 5, (20, 1): 5, (20, 2): 5, (20, 3): 5, (21, 0): 5, (21, 1): 5, (21, 2): 5, (21, 3): 5, (22, 0): 5, (22, 1): 5, (22, 2): 5, (22, 3): 5, (23, 0): 5, (23, 1): 5, (23, 2): 5, (23, 3): 5, (24, 0): 5, (24, 1): 5, (24, 2): 5, (24, 3): 5, (25, 0): 5, (25, 1): 5, (25, 2): 5, (25, 3): 5, (26, 0): 5, (26, 1): 5, (26, 2): 5, (26, 3): 5, (27, 0): 5, (27, 1): 5, (27, 2): 5, (27, 3): 5, (28, 0): 5, (28, 1): 5, (28, 2): 5, (28, 3): 5, (29, 0): 5, (29, 1): 5, (29, 2): 5, (29, 3): 5, (30, 0): 5, (30, 1): 5, (30, 2): 5, (30, 3): 5, (31, 0): 5, (31, 1): 5, (31, 2): 5, (31, 3): 5, (32, 0): 0, (32, 1): 5, (32, 2): 5, (32, 3): 5, (33, 0): 0, (33, 1): 5, (33, 2): 5, (33, 3): 5, (34, 0): 0, (34, 1): 5, (34, 2): 5, (34, 3): 5, (35, 0): 0, (35, 1): 5, (35, 2): 5, (35, 3): 5, (36, 0): 0, (36, 1): 5, (36, 2): 5, (36, 3): 5, (37, 0): 0, (37, 1): 5, (37, 2): 5, (37, 3): 5, (38, 0): 0, (38, 1): 5, (38, 2): 5, (38, 3): 5, (39, 0): 0, (39, 1): 5, (39, 2): 5, (39, 3): 8, (40, 0): 5, (40, 1): 5, (40, 2): 8, (40, 3): 8, (41, 0): 5, (41, 1): 4, (41, 2): 8, (41, 3): 8, (42, 0): 2, (42, 1): 8, (42, 2): 8, (42, 3): 8, (43, 0): 8, (43, 1): 8, (43, 2): 8, (43, 3): 8, (44, 0): 8, (44, 1): 8, (44, 2): 8, (44, 3): 8, (45, 0): 8, (45, 1): 8, (45, 2): 8, (45, 3): 8, (46, 0): 8, (46, 1): 8, (46, 2): 8, (46, 3): 8, (47, 0): 8, (47, 1): 8, (47, 2): 8, (47, 3): 8, (48, 0): 8, (48, 1): 8, (48, 2): 8, (48, 3): 3, (49, 0): 8, (49, 1): 8, (49, 2): 3, (49, 3): 1})\n",
        "current_mover_state =env.reset()\n",
        "\n",
        "for i in range(100):\n",
        "    action_index = estimated_policy[current_mover_state]\n",
        "    next_state, reward, done = env.step(current_mover_state, action_index)\n",
        "    print(f\"Step {i+1}: State: {current_mover_state},  action: {env.moves[action_index]}, Next State: {next_state}, Reward: {reward}, resources : {env.resources}\")\n",
        "    current_mover_state = next_state\n",
        "    if done:\n",
        "      break\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IzlB804VBy1O"
      },
      "execution_count": 260,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tabulate import tabulate\n",
        "\n",
        "moves = ['↑', '↓', '←', '→']\n",
        "\n",
        "data = estimated_policy\n",
        "\n",
        "matrix_size = 7  # This should match the highest index values used in your data dictionary\n",
        "\n",
        "confusion_matrix = np.full((matrix_size, matrix_size), '', dtype=object)\n",
        "\n",
        "for (x, y), value in data.items():\n",
        "    if value in range(len(moves)):  # Ensure that the index value is valid\n",
        "        confusion_matrix[y, x] = moves[value]  # Note the inversion of indices for y, x\n",
        "    else:\n",
        "        confusion_matrix[y, x] = 'Invalid'  # Handle invalid data gracefully\n",
        "\n",
        "confusion_matrix = np.flipud(confusion_matrix)\n",
        "\n",
        "labels = [str(i) for i in range(matrix_size)]\n",
        "confusion_matrix[0,6] = 'Done'\n",
        "# Generate a textual representation of the matrix using tabulate\n",
        "table = tabulate(confusion_matrix, headers=labels, tablefmt=\"grid\", showindex=labels[::-1])\n",
        "\n",
        "print(table)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbvP3T9ydMnR",
        "outputId": "c8d1b652-e83d-47a5-afb7-0aea9655cd53"
      },
      "execution_count": 261,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+-----+-----+-----+-----+-----+------+\n",
            "|    | 0   | 1   | 2   | 3   | 4   | 5   | 6    |\n",
            "+====+=====+=====+=====+=====+=====+=====+======+\n",
            "|  6 | ←   | ↓   | →   | ↓   | ↑   | →   | Done |\n",
            "+----+-----+-----+-----+-----+-----+-----+------+\n",
            "|  5 | →   | ↓   | ↑   | ↓   | →   | →   | ↑    |\n",
            "+----+-----+-----+-----+-----+-----+-----+------+\n",
            "|  4 | ↑   | ↑   | ↓   | ↓   | ↓   | ↓   | ↑    |\n",
            "+----+-----+-----+-----+-----+-----+-----+------+\n",
            "|  3 | ↓   | ↑   | ↓   | ↓   | ←   | ↓   | ↑    |\n",
            "+----+-----+-----+-----+-----+-----+-----+------+\n",
            "|  2 | ←   | ↓   | ↓   | ↑   | ↓   | →   | ↑    |\n",
            "+----+-----+-----+-----+-----+-----+-----+------+\n",
            "|  1 | →   | ↓   | →   | →   | →   | ↑   | ↑    |\n",
            "+----+-----+-----+-----+-----+-----+-----+------+\n",
            "|  0 | →   | →   | →   | ↑   | ←   | →   | ↑    |\n",
            "+----+-----+-----+-----+-----+-----+-----+------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pbnuiowso8Xq"
      },
      "execution_count": 257,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aDVIfOHwFu--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7kAlV8f-p5bg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}